{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a866525",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>Graph Dataset Construction</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a6e12",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The following notebook takes as input the pickle files that represent graph data and outputs them with a format that will be suitable for the current graph kernels approach.\n",
    "\n",
    "    \n",
    "In more detail: \n",
    "\n",
    "Input: This is a list of 5074 dataframes each dataframe describes a graph for a timestep. Every dataframe has 222 rows that represent the parking sectors and the features are described by the columns.\n",
    "\n",
    "Output: This is a list of 5074 lists. Each list consists of 3 elements. [set, dict1, dict2]\n",
    "- Set: Describes the graph edges and have the format = set (int,int) \"example = (node1,node2)\"\n",
    "- Dict1: Describes the node features and have the format = dict {key(int) : values(array)} \"example = {node1 :  [f1,f2,...,fn]}\"\n",
    "- Dict2: Describes the edge weights and have the format dict = {key(set) : value(int)} \"example = {(node1,node2) : weight}\"\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae89bde",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "In the data, we have as input, the node ids that represent a parking sector are the same at each time step.\n",
    "The present approach requires node ids to be unique across the graphs. For this reason, we implemented a kind of mapping so that node ids are unique.   \n",
    "<br>  \n",
    "<br>\n",
    "- PS1: At the end of this notebook, we apply the same procces for ChinckenPox dataset in order to have 2 graph datasets to make experiments using our methods.  \n",
    "<br>\n",
    "- PS2: Both Train-test targets are processed in a subsequent notebook.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db13a8",
   "metadata": {},
   "source": [
    "## Generals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc0d701",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Packages import and system configurations. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a95056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "project_path = '/Users/nickkarras/PycharmProjects/Graph_Based_SVR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186a34b",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Datasets paths. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path_park = project_path + '/Data/ParkingViolationPrediction/Init/Train_Dataset_Graph.pkl'\n",
    "test_dataset_path_park = project_path + '/Data/ParkingViolationPrediction/Init/Test_Dataset_Graph.pkl'\n",
    "edges_path_park = project_path+'/Data/ParkingViolationPrediction/Init/Edges_Weights.csv'\n",
    "\n",
    "train_dataset_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Train_data.pkl'\n",
    "test_dataset_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Test_data.pkl'\n",
    "edges_path_chic = project_path + '/Data/Chickenpox/Init/Chickenpox_Edges.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a3f7a",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "Function that saves objects to pickle files. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b69499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a86c83",
   "metadata": {},
   "source": [
    "## Core functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c7937",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "The following function takes as input a list that represents node id mapping.\n",
    "    \n",
    "    \n",
    "Returns the set of edges and the dict of edge weights for each graph. Also, change node id according to the given mapping list.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19459345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_weights_preprocessing(edges_path,mapping):\n",
    "    edges_df = pd.read_csv(edges_path,sep=',', index_col=0)\n",
    "    edges_df[\"Node1\"] = edges_df[\"Node1\"].map(mapping)\n",
    "    edges_df[\"Node2\"] = edges_df[\"Node2\"].map(mapping)\n",
    "    \n",
    "    edges = edges_df.drop(['Weights'], axis=1)\n",
    "    tmp_ls = edges.to_numpy().tolist()\n",
    "    edges = set(map(tuple,tmp_ls))\n",
    "    \n",
    "    edge_weights = edges_df.copy()\n",
    "    edge_weights['Combinations'] = list(zip(edges_df.Node1, edges_df.Node2))\n",
    "    edge_weights = edge_weights[['Combinations','Weights']]\n",
    "    edge_weights = edge_weights.set_index('Combinations').T.to_dict('records')\n",
    "    \n",
    "    return edges,edge_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c447371",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The following function create the node features dict for each graph and rename the node ids.\n",
    "Also create the a list that map the old node id with the new ones.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_features_preprocesing_parking(path):\n",
    "    with open(path, 'rb') as inp:\n",
    "        node_features = pickle.load(inp)\n",
    "    names1 = ['Node_Id','Date_Sin','Holidays','Capacity','temp','humidity','Week_Day_Sin','Month_Sin',\n",
    "              'Real_Time','Γενικό Νοσοκομείο Θεσσαλονίκης «Γ. Γεννηματάς»', 'Λιμάνι' ,'Δημαρχείο Θεσσαλονίκης',\n",
    "              'Λευκός Πύργος','Αγορά Καπάνι','Λαδάδικα','Πλατεία Άθωνος','Πλατεία Αριστοτέλους','Ροτόντα',\n",
    "              'Πλατεία Αγίας Σοφίας','Πλατεία Αντιγονιδών','Μουσείο Μακεδονικού Αγώνα','Πλατεία Ναυαρίνου',\n",
    "              'Πάρκο ΧΑΝΘ','Ιερός Ναός Αγίου Δημητρίου','ΔΕΘ','ΑΠΘ','Άγαλμα Ελευθερίου Βενιζέλου',\n",
    "              'Ρωμαϊκή Αγορά Θεσσαλονίκης','Predictions']\n",
    "    names2 = ['Init_Node_Id','Node_Id']\n",
    "    mapping_list = []\n",
    "    n1 = 1\n",
    "    for i in tqdm (range (0,len(node_features))):\n",
    "        node_features[i] = node_features[i].sort_values(\"Slot_id\")\n",
    "        node_features[i] = node_features[i].reset_index()  \n",
    "        node_features[i]['Init_Node_Id'] = node_features[i].index\n",
    "        node_features[i]['Node_Id'] = np.arange(n1, n1+len(node_features[i]))\n",
    "        n1 = n1 + len(node_features[i])        \n",
    "        mapping_list.append(node_features[i][names2].set_index('Init_Node_Id').T.to_dict('records'))\n",
    "        \n",
    "        node_features[i] = node_features[i][names1]\n",
    "        node_features[i] = node_features[i].set_index('Node_Id').T.to_dict('list')\n",
    "    return node_features,mapping_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0293cd25",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The following function combines the above 2 functions and create the list with the final graphs \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a516979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(dataset_path,edges_path,mode):\n",
    "    G = []\n",
    "    print (f\"Creating {mode} Node Features\")\n",
    "    node_features_dict,mapping_list = node_features_preprocesing_parking(dataset_path)\n",
    "    print (f\"Create {mode} Graphs List\")\n",
    "    for i in tqdm (range (0,len(node_features_dict))):\n",
    "        graph_list=[]\n",
    "        edges_set,edge_weights_dict = edge_weights_preprocessing(edges_path,mapping_list[i][0])\n",
    "        graph_list.append(edges_set)\n",
    "        graph_list.append(node_features_dict[i])\n",
    "        graph_list.append(edge_weights_dict)\n",
    "        G.append(graph_list)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd606e6d",
   "metadata": {},
   "source": [
    "## Create and Save Graphs Parking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353de436",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = create_graph(train_dataset_path_park,edges_path_park,'Train')\n",
    "save_object(G_train, 'Data/ParkingViolationPrediction/G_Train.pkl')\n",
    "G_test = create_graph(test_dataset_path_park,edges_path_park,'Test')\n",
    "save_object(G_test, 'Data/ParkingViolationPrediction/G_Test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc3892",
   "metadata": {},
   "source": [
    "## Create and Save Graphs ChinckenPox Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bece8",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The following function create the node features dict for each graph and rename the node ids.\n",
    "Also create the a list that map the old node id with the new ones.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f01a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_features_preprocesing_chicken(path):\n",
    "    with open(path, 'rb') as inp:\n",
    "        node_features = pickle.load(inp)\n",
    "        \n",
    "    names = ['Init_Node_Id','Node_Id']\n",
    "    mapping_list = []\n",
    "    n1 = 1\n",
    "    for i in tqdm (range (0,len(node_features))):\n",
    "        node_features[i]['Init_Node_Id'] = node_features[i].index\n",
    "        node_features[i]['Node_Id'] = np.arange(n1, n1+len(node_features[i]))\n",
    "        n1 = n1 + len(node_features[i])        \n",
    "        mapping_list.append(node_features[i][names].set_index('Init_Node_Id').T.to_dict('records'))\n",
    "        node_features[i] = node_features[i].set_index('Node_Id').T.to_dict('list')\n",
    "    return node_features,mapping_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec48ae5",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The following function combines the above 2 functions and create the list with the final graphs \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73696e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_chic(dataset_path,edges_path,mode):\n",
    "    G = []\n",
    "    print (f\"Creating {mode} Node Features\")\n",
    "    node_features_dict,mapping_list = node_features_preprocesing_chicken(dataset_path)\n",
    "    print (f\"Create {mode} Graphs List\")\n",
    "    for i in tqdm (range (0,len(node_features_dict))):\n",
    "        graph_list=[]\n",
    "        edges_set,edge_weights_dict = edge_weights_preprocessing(edges_path,mapping_list[i][0])\n",
    "        graph_list.append(edges_set)\n",
    "        graph_list.append(node_features_dict[i])\n",
    "        graph_list.append(edge_weights_dict)\n",
    "        G.append(graph_list)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd40b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = create_graph_chic(train_dataset_path_chic,edges_path_chic,'Train')\n",
    "save_object(G_train, 'Data/Chickenpox/G2_Train.pkl')\n",
    "G_test = create_graph_chic(test_dataset_path_chic,edges_path_chic,'Test')\n",
    "save_object(G_test, 'Data/Chickenpox/G2_Test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full_ml",
   "language": "python",
   "name": "full_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
